activation: 'LeakyReLU' # Can be either 'ReLU' or 'LeakyReLU'

# STRUCTURAL PARAMETERS
mu: 50          # history of inputs considered
my: 0          # history of outputs considered
hlszs: [10]  # sizes of only hidden layers (input and output layers' sizes are implicit from other factors)

# LEARNING PARAMETERS
bsz: 64         # batch size
e: 200          # epochs
p: 4            # patience

# OPTIMIZER PARAMETERS
lr: 0.001       # learning rate
weight_decay: 0.1